#!/usr/bin/env python3
"""
YOLOS + DBSCAN ìƒ‰ìƒ í´ëŸ¬ìŠ¤í„°ë§
"""

import cv2
import numpy as np
from sklearn.cluster import DBSCAN
import matplotlib.pyplot as plt
import pandas as pd
from transformers import AutoImageProcessor, YolosForObjectDetection
import torch
from PIL import Image

class YOLOSColorClustering:
    def __init__(self):
        """YOLOS ëª¨ë¸ ì´ˆê¸°í™”"""
        print("ğŸ”„ YOLOS ëª¨ë¸ ë¡œë”© ì¤‘...")
        
        # 1. YOLOS ëª¨ë¸ ë¡œë”©
        self.processor = AutoImageProcessor.from_pretrained("valentinafeve/yolos-fashionpedia")
        self.model = YolosForObjectDetection.from_pretrained("valentinafeve/yolos-fashionpedia")
        
        print("âœ… YOLOS ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
        
        # í´ë˜ìŠ¤ ì´ë¦„ ì •ë³´ (Fashionpedia ë°ì´í„°ì…‹ ê¸°ì¤€)
        self.class_names = {
            0: 'shirt, blouse',
            1: 'top, t-shirt, sweatshirt', 
            2: 'sweater',
            3: 'cardigan',
            4: 'jacket',
            5: 'vest',
            6: 'pants',
            7: 'shorts',
            8: 'skirt',
            9: 'coat',
            10: 'dress',
            11: 'jumpsuit',
            12: 'cape',
            13: 'glasses',
            14: 'hat',
            15: 'headband, head covering, hair accessory',
            16: 'tie',
            17: 'glove',
            18: 'watch',
            19: 'belt',
            20: 'leg warmer',
            21: 'tights, stockings',
            22: 'sock',
            23: 'shoe',
            24: 'bag, wallet',
            25: 'scarf',
            26: 'umbrella',
            27: 'hood',
            28: 'collar',
            29: 'lapel',
            30: 'epaulette',
            31: 'sleeve',
            32: 'pocket',
            33: 'neckline',
            34: 'buckle',
            35: 'zipper',
            36: 'applique',
            37: 'bead',
            38: 'bow',
            39: 'flower',
            40: 'fringe',
            41: 'ribbon',
            42: 'rivet',
            43: 'ruffle',
            44: 'sequin',
            45: 'tassel'
        }
    
    def detect_clothing(self, image_path, conf_threshold=0.3):
        """YOLOSë¡œ ì˜ë¥˜ ê°ì²´ ê°ì§€"""
        
        # ì´ë¯¸ì§€ ë¡œë“œ
        image = Image.open(image_path)
        
        # ì „ì²˜ë¦¬
        inputs = self.processor(images=image, return_tensors="pt")
        
        # ì¶”ë¡ 
        with torch.no_grad():
            outputs = self.model(**inputs)
        
        # í›„ì²˜ë¦¬
        target_sizes = torch.tensor([image.size[::-1]])
        results = self.processor.post_process_object_detection(
            outputs, target_sizes=target_sizes, threshold=conf_threshold
        )[0]
        
        # ê²°ê³¼ ë³€í™˜
        detected_boxes = []
        for score, label, box in zip(results["scores"], results["labels"], results["boxes"]):
            detected_boxes.append({
                'bbox': box.tolist(),  # [x1, y1, x2, y2]
                'confidence': score.item(),
                'class_id': label.item(),
                'class_name': self.class_names.get(label.item(), f'Class_{label.item()}')
            })
        
        return detected_boxes
    
    def analyze_color_clustering(self, image_path, conf_threshold=0.3):
        """YOLOS + DBSCAN ìƒ‰ìƒ í´ëŸ¬ìŠ¤í„°ë§ ë¶„ì„"""
        
        print("ğŸ¨ YOLOS + DBSCAN ìƒ‰ìƒ í´ëŸ¬ìŠ¤í„°ë§ ë¶„ì„")
        print("=" * 60)
        
        # 1. YOLOS ê°ì²´ ê°ì§€
        print("1. YOLOS ê°ì²´ ê°ì§€ ì¤‘...")
        detected_boxes = self.detect_clothing(image_path, conf_threshold)
        print(f"âœ… ê°ì§€ëœ ê°ì²´: {len(detected_boxes)}ê°œ")
        
        if not detected_boxes:
            print("âŒ ê°ì§€ëœ ê°ì²´ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return []
        
        # 2. ì´ë¯¸ì§€ ë¡œë“œ
        image = cv2.imread(image_path)
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        all_results = []
        
        # 3. ê° ê°ì§€ëœ ì˜ì—­ì— ëŒ€í•´ ìƒ‰ìƒ ë¶„ì„
        print("\n2. ê° ì˜ì—­ë³„ ìƒ‰ìƒ ë¶„ì„...")
        
        for i, detection in enumerate(detected_boxes):
            bbox = detection['bbox']
            confidence = detection['confidence']
            class_id = detection['class_id']
            class_name = detection['class_name']
            
            print(f"\nğŸ“Š ì˜ì—­ {i+1} ë¶„ì„:")
            print(f"  í´ë˜ìŠ¤: {class_name} (ID: {class_id})")
            print(f"  ì‹ ë¢°ë„: {confidence:.3f}")
            print(f"  ë°”ìš´ë”© ë°•ìŠ¤: {bbox}")
            
            # ë°”ìš´ë”© ë°•ìŠ¤ë¡œ ì˜ì—­ ì¶”ì¶œ
            x1, y1, x2, y2 = [int(coord) for coord in bbox]
            region = image_rgb[y1:y2, x1:x2]
            
            if region.size == 0:
                print("  âš ï¸ ì˜ì—­ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                continue
            
            # ë°°ê²½ ì œê±° ì‹œë„
            region_hsv = cv2.cvtColor(region, cv2.COLOR_RGB2HSV)
            mask = np.ones(region.shape[:2], dtype=bool)
            
            # ëª…ë„ì™€ ì±„ë„ ê¸°ë°˜ ë°°ê²½ ì œê±°
            value_mask = (region_hsv[:, :, 2] > 50) & (region_hsv[:, :, 2] < 220)
            saturation_mask = region_hsv[:, :, 1] > 20
            mask = mask & value_mask & saturation_mask
            
            filtered_region = region.copy()
            filtered_region[~mask] = [0, 0, 0]
            
            valid_pixels = np.sum(mask)
            if valid_pixels < 1000:
                print("  âš ï¸ ë°°ê²½ ì œê±° í›„ ìœ íš¨í•œ í”½ì…€ì´ ì ì–´ ì›ë³¸ ì‚¬ìš©")
                filtered_region = region
            else:
                print(f"  ğŸ¯ ë°°ê²½ ì œê±°: {region.size//3} -> {valid_pixels} í”½ì…€")
            
            # ì˜ì—­ í¬ê¸° ì¡°ì •
            height, width = filtered_region.shape[:2]
            if height * width > 100000:
                scale_factor = np.sqrt(100000 / (height * width))
                new_width = int(width * scale_factor)
                new_height = int(height * scale_factor)
                filtered_region = cv2.resize(filtered_region, (new_width, new_height))
                print(f"  ğŸ“ ì˜ì—­ í¬ê¸° ì¡°ì •: {width}x{height} -> {new_width}x{new_height}")
            
            region = filtered_region
            
            # 4. ìƒ‰ìƒ í´ëŸ¬ìŠ¤í„°ë§
            pixel_colors = region.reshape((-1, 3))
            print(f"  ğŸ” ë¶„ì„í•  í”½ì…€ ìˆ˜: {len(pixel_colors)}")
            
            # HSV ë³€í™˜
            pixel_colors_hsv = cv2.cvtColor(region, cv2.COLOR_RGB2HSV)
            pixel_colors_hsv = pixel_colors_hsv.reshape((-1, 3))
            
            # ì±„ë„ ê°’ ì¶”ì¶œ
            saturation_values = pixel_colors_hsv[:, 1]
            saturation_value_data = saturation_values.reshape(-1, 1)
            
            # DBSCAN í´ëŸ¬ìŠ¤í„°ë§
            dbscan = DBSCAN(eps=0.3, min_samples=1000)
            dbscan.fit(saturation_value_data)
            labels = dbscan.labels_
            
            # í´ëŸ¬ìŠ¤í„° ë¶„ì„
            n_clusters = len(set(labels)) - (1 if -1 in labels else 0)
            n_noise = list(labels).count(-1)
            
            print(f"  ğŸ¯ ë°œê²¬ëœ í´ëŸ¬ìŠ¤í„°: {n_clusters}ê°œ")
            print(f"  ğŸ“Š ë…¸ì´ì¦ˆ í”½ì…€: {n_noise}ê°œ")
            
            # í´ëŸ¬ìŠ¤í„°ë³„ í‰ê·  ì±„ë„ ê³„ì‚°
            df_clusters = pd.DataFrame({
                'saturation': saturation_value_data.flatten(),
                'cluster': labels
            })
            
            df_filtered = df_clusters[df_clusters['cluster'] != -1].copy()
            
            if len(df_filtered) > 0:
                mean_saturation_per_cluster = df_filtered.groupby('cluster')[['saturation']].mean()
                print(f"  ğŸ“ˆ í´ëŸ¬ìŠ¤í„°ë³„ í‰ê·  ì±„ë„:")
                for cluster_id, mean_sat in mean_saturation_per_cluster.iterrows():
                    print(f"    í´ëŸ¬ìŠ¤í„° {cluster_id}: {mean_sat['saturation']:.1f}")
                
                # í™”ë ¤í•¨ ì ìˆ˜ ê³„ì‚°
                filtered_saturation_values = df_filtered['saturation']
                max_overall_saturation = filtered_saturation_values.max()
                vibrancy_score = (max_overall_saturation / 255.0) * 2 - 1
                
                print(f"  ğŸ“Š ì˜ì—­ ë¶„ì„ ê²°ê³¼:")
                print(f"    ìµœëŒ€ ì±„ë„: {max_overall_saturation:.1f}")
                print(f"    í™”ë ¤í•¨ ì ìˆ˜: {vibrancy_score:.3f}")
                
                all_results.append({
                    'region_id': i,
                    'class_id': class_id,
                    'class_name': class_name,
                    'confidence': confidence,
                    'bbox': bbox,
                    'score': vibrancy_score,
                    'max_saturation': max_overall_saturation,
                    'n_clusters': n_clusters,
                    'n_noise': n_noise,
                    'labels': labels,
                    'region_shape': region.shape
                })
            else:
                print(f"  âš ï¸ ìœ íš¨í•œ í´ëŸ¬ìŠ¤í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # 5. ì „ì²´ ê²°ê³¼ ìš”ì•½
        print(f"\nğŸ“‹ ì „ì²´ ë¶„ì„ ê²°ê³¼ ìš”ì•½:")
        print(f"ë¶„ì„ëœ ì˜ì—­ ìˆ˜: {len(all_results)}")
        
        if all_results:
            avg_score = np.mean([r['score'] for r in all_results])
            print(f"ì „ì²´ í‰ê·  ì ìˆ˜: {avg_score:.3f}")
            
            print(f"\nğŸ“Š ê° ì˜ì—­ë³„ ìµœëŒ€ ì±„ë„:")
            for result in all_results:
                print(f"  ì˜ì—­ {result['region_id']+1}: {result['max_saturation']:.1f}")
        
        return all_results

def visualize_results(image, results):
    """ê²°ê³¼ ì‹œê°í™” - í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ í¬í•¨"""
    
    if not results:
        print("ì‹œê°í™”í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    n_results = len(results)
    fig, axes = plt.subplots(2, n_results, figsize=(5*n_results, 10))
    
    if n_results == 1:
        axes = axes.reshape(2, 1)
    
    for i, result in enumerate(results):
        bbox = result['bbox']
        confidence = result['confidence']
        score = result['score']
        max_sat = result['max_saturation']
        labels = result['labels']
        region_shape = result['region_shape']
        class_name = result['class_name']
        
        x1, y1, x2, y2 = [int(coord) for coord in bbox]
        
        # 1. ì›ë³¸ ì´ë¯¸ì§€ì— ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
        axes[0, i].imshow(image)
        axes[0, i].set_title(f'{class_name} (Score: {score:.3f})')
        
        rect = plt.Rectangle((x1, y1), x2-x1, y2-y1, 
                           fill=False, color='red', linewidth=2)
        axes[0, i].add_patch(rect)
        
        label_text = f'ì‹ ë¢°ë„:{confidence:.2f}\nì ìˆ˜:{score:.2f}\nìµœëŒ€ì±„ë„:{max_sat:.0f}'
        axes[0, i].text(x1, y1-10, label_text, fontsize=8, color='red', 
                    weight='bold', bbox=dict(facecolor='white', alpha=0.7))
        axes[0, i].axis('off')
        
        # 2. í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ ì‹œê°í™”
        if 'labels' in result and labels is not None:
            height, width = region_shape[:2]
            clustered_image = np.zeros((height, width, 3), dtype=np.uint8)
            
            n_clusters = len(set(labels)) - (1 if -1 in labels else 0)
            
            import random
            cluster_colors = {j: (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)) 
                            for j in range(n_clusters)}
            noise_color = (0, 0, 0)
            
            for idx, label in enumerate(labels):
                row = idx // width
                col = idx % width
                if row < height and col < width:
                    if label == -1:
                        clustered_image[row, col] = noise_color
                    else:
                        clustered_image[row, col] = cluster_colors[label]
            
            axes[1, i].imshow(clustered_image)
            axes[1, i].set_title(f'DBSCAN Clustering\n({n_clusters} clusters)')
            axes[1, i].axis('off')
        else:
            axes[1, i].text(0.5, 0.5, 'No clustering\nresult', 
                           ha='center', va='center', transform=axes[1, i].transAxes)
            axes[1, i].set_title('No Clustering')
            axes[1, i].axis('off')
    
    plt.tight_layout()
    plt.show()

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    analyzer = YOLOSColorClustering()
    results = analyzer.analyze_color_clustering("dataset/maximal/0269be0620747ecd46cd060a240b81b0.jpg")
    
    if results:
        image = cv2.imread("dataset/maximal/0269be0620747ecd46cd060a240b81b0.jpg")
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        visualize_results(image_rgb, results) 